# 통계 종류

## 리스트 페이지

+ 현재 목적지로의 총 운항 횟수(고려) | 현재 목적지로의 지연률(통계) | 현재 목적지로의 평균 지연시간  (텍스트) | 현재 목적지로의 지연시간(예측) 

<br/>

## 상세 페이지

> https://ichi.pro/ko/django-mich-chart-jsleul-sayonghayeo-daehwa-hyeong-deiteo-sigaghwa-mandeulgi-154262534911758

+ 리뷰 워드 클라우드
+ 항공사의 통합 지연률 | 현재 목적지로의 총 운항 횟수 | 현재 목적지로의 지연률(통계) | 현재 목적지로의 평균 지연시간  (텍스트)
+ 10분 이내 출발율 | 30분 이내 출발율 | 30분 초과 지연 (텍스트)
+ **항공사의 지연시간 평균 시계열 막대 차트** | **항공사의 월별 이용객수 추이 시계열 꺾은선 차트** | **항공사의 통합 지연 사유 파이차트** 
+ **해당 목적지로의 지연 사유 파이차트** | **지연 사유별 평균 지연 시간 막대 그래프** 
+ 머신러닝 그래프
  + 변수 3개(도착지, 항공사 + 기상 / 이용객)
    + **해당 목적지로의 기상별 지연률, 지연시간 예측 (그래프)**
    + **해당 목적지로의 월별(이용객별) 지연률, 지연시간 예측  (월별/이용객수별 그래프)**
  + 변수 4개(도착지, 항공사, 기상, 이용객)
    + **해당 목적지로의 오늘 기상, 이달의 이용객수를 기반으로 한 지연률, 지연시간 예측값**

<br/>

## 머신 러닝 모델

> 지수평활법, Multivariable Linear Regression

+ 원핫인코딩을 통해 범주형 변수인 도착지, 항공사, 기상을 수치값으로 변환

+ 올해/향후 12개월 월별 이용객수 예측

  + 지수평활법 모형 훈련 및 예측
  + https://rfriend.tistory.com/671
  + https://statkclee.github.io/statistics/stat-time-series-forecast.html
  + MAPE가 가장 작은 모델을 사용

+ 해당 목적지로의 기상별 지연시간 예측

  + ```
    H(도착지, 항공사, 기상) = w1*도착지 + w2*항공사 + w3*기상 + b
    ```

  + 각 기상(비, 눈, 태풍, 낙뢰 등) 별로 머신러닝 모델을 통해 H(x)값을 구한 후, 이를 그래프로 표현한다.

+ 해당 목적지로의 월별(이용객별) 지연시간 예측

  + ```
    H(도착지, 항공사, 월별 이용객수) = w1*도착지 + w2*항공사 + w3*월별 이용객수 + b
    ```

  + 각 월별 이용객수를 통해 향후 12개월의 지연시간을 예측하고 이를 그래프로 표현한다.

+ 해당 목적지로의 오늘 기상, 이달의 이용객수를 기반으로 한 지연시간 예측

  + ```
    H(도착지, 항공사, 기상, 월별 이용객수) = w1*도착지 + w2*항공사 + w3*기상 + w4*월별 이용객수 + b
    ```

  + 4개의 변수를 사용한 모델을 만들고, 각 값을 넣어 예측값을 도출

<br/>

## 항공 데이터 셋 예시

### 항공기 출발 데이터

https://www.notion.so/jiu-park/bfcc7248ca1844deb2bcdb2f16a9178f#e733620d21f34eccb40d990e4608763d

| 날짜       | 목적지      | 항공사       | 계획시각 | 출발시각 | 지연시간(분) | 지연여부 | 지연사유              |
| ---------- | ----------- | ------------ | -------- | -------- | ------------ | -------- | --------------------- |
| 2021-09-15 | NGO(나고야) | 대한항공     | 08:10    | 08:15    | 5            | N        | N                     |
| 2021-09-14 | CGQ(장춘)   | 아시아나항공 | 08:10    | 09:42    | 92           | Y        | 기상-시정에 의한 지연 |

### 월별 이용객수 데이터

https://www.notion.so/jiu-park/bfcc7248ca1844deb2bcdb2f16a9178f#f5db3bcb94bd49e090036c8aebe79362

| 년도 | 월   | 항공사   | 여객수 |
| ---- | ---- | -------- | ------ |
| 2021 | 8    | 대한항공 | 534847 |

### 기상 데이터 (40년치 데이터 : 시간별로 데이터 존재)

https://www.notion.so/jiu-park/bfcc7248ca1844deb2bcdb2f16a9178f#13aea472c0be44bbb252cf564cd3c4cf

| 날짜       | 기상 상태 |
| ---------- | --------- |
| 2021-09-15 | Clear Sky |

<br/>

## 원핫인코딩

+ 특성에 들어있는 고유한 값마다 새로운 dummy 특성을 만드는 방법이다.
+ 원핫인코딩을 통해 범주를 벡터화하여 해당 튜플에서 해당하는 범주만 1, 나머지 범주는 0을 갖도록 할 수 있다.
  + 범주형 변수의 범주가 4개라면 총 4개의 열이 생성된다.
  + ex) 빨, 주, 노, 초이며 현재 튜플이 빨강이라면 빨강만 1, 나머지는 0의 값을 갖는다.
+ 하지만, 이렇게 되면 빨, 주, 노, 초의 열들의 값이 항상 다 더하면 1이 되는 관계를 갖는다.
  + 이러한 선형 관계 때문에 생기는 문제가 **다중공선성**이다.
+ 이를 해결하기 위해서는 위와 같은 `빨 + 주 + 노 + 초 = 1`이라는 관계를 없애줘야 한다.
  + 이때 사용하는 방법이 범주를 벡터화한 열 중 하나를 없애는 것이다. (주로 첫 번째 것을 없앤다. drop_first=True)
  + 즉, 주, 노, 초로만 나눠 놓고 주, 노, 초가 전부 0인 경우 이 튜플이 빨강임을 알 수 있기 때문에 데이터의 문제는 없으면서 선형 관계가 생기지 않는다.
  + https://towardsdatascience.com/one-hot-encoding-multicollinearity-and-the-dummy-variable-trap-b5840be3c41a
  + https://dnai-deny.tistory.com/12
+ 따라서, 결과적으로 범주의 개수가 N개인 범주형 변수를 적절하게 원핫이코딩하면 총 N-1개의 열이 생성된다.

### 어려움

+ 원핫인코딩 시에는 다중공선성을 신경써야 한다는 것
+ 원핫인코딩으로 인해 범주가 너무 많이 나뉘면 칼럼이 많이 생기기 때문에 메모리 문제, 모델이 제대로 해당 범주형 변수를 반영하지 못한다는 문제(구글링 결과 범주가 너무 많으면 모델에서 학습에 별로 영향을 안미치는 변수로 취급한다고 함)
+ 원핫인코딩 자체가 다중선형회귀에 적합하지 않을 수도 있다는 것
  + 따라서, 실제 데이터로 train / test 셋을 나눠서 평가를 해봐야 한다.

<br/>

## 예시 코딩

### 로지스틱 회귀

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
flight = ['대한', '아시아나', '아시아나', '대한', '대한', '진에어', '아시아나', '진에어', '진에어', '진에어', '대한', '아시아나', '아시아나', '대한', '아시아나', '아시아나', '대한', '대한', '대한', '진에어', '진에어', '진에어', '진에어', '진에어', '진에어', '대한', '아시아나', '대한', '아시아나'] * 100000
weather = ['맑음', '비', '눈', '낙뢰', '맑음', '맑음', '맑음', '비', '눈', '눈', '비', '비', '낙뢰', '낙뢰', '눈', '맑음', '맑음', '눈', '비', '맑음', '눈', '비', '낙뢰', '맑음', '비', '비', '눈', '맑음', '낙뢰'] * 100000
late = [0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1] * 100000
cols = ['flight', 'weather', 'late']
df = pd.DataFrame(list(map(list, zip(flight, weather, late))), columns=cols)
# 다중공선성 제거를 위해 pd.get_dummies에서 첫 범주를 삭제
train = pd.get_dummies(df, drop_first=True)
# 0번째 열이 '지연여부'로 들어감
X = train[train.columns[1:]].to_numpy()
Y = train[train.columns[0]].to_numpy()
train_input, test_input, train_target, test_target = train_test_split(X, Y, random_state=42)
lr = LogisticRegression()
lr.fit(train_input, train_target)
np.set_printoptions(precision=6, suppress=True)
print(train_input)
print(lr.predict(train_input[:]))
# [0 0 1 ... 1 0 0]
print(lr.predict_proba(train_input[:]))
# [[0.999865 0.000135]
#  [0.999884 0.000116]
#  [0.000009 0.999991]
#  ...
#  [0.000133 0.999867]
#  [0.999865 0.000135]
#  [0.999856 0.000144]]
print(lr.score(train_input, train_target))
# 0.9654850574712643
print(lr.score(test_input, test_target))
# 0.9656137931034483
```

<br/>

### 다중선형회귀

```python
from sklearn.linear_model import LinearRegression
flight = ['대한', '아시아나', '아시아나', '대한', '대한', '진에어', '아시아나', '진에어', '진에어', '진에어', '대한', '아시아나', '아시아나', '대한', '아시아나', '아시아나', '대한', '대한', '대한', '진에어', '진에어', '진에어', '진에어', '진에어', '진에어', '대한', '아시아나', '대한', '아시아나'] * 1000000
weather = ['맑음', '비', '눈', '낙뢰', '맑음', '맑음', '맑음', '비', '눈', '눈', '비', '비', '낙뢰', '낙뢰', '눈', '맑음', '맑음', '눈', '비', '맑음', '눈', '비', '낙뢰', '맑음', '비', '비', '눈', '맑음', '낙뢰'] * 1000000
late = [5, 15, 30, 60, 3, 4, 10, 20, 25, 35, 17, 10, 50, 100, 50, 10, 2, 25, 13, 0, 20, 12, 45, 6, 17, 17, 28, 3, 30] * 1000000
cols = ['flight', 'weather', 'late']
df = pd.DataFrame(list(map(list, zip(flight, weather, late))), columns=cols)
print(df[:29])
#    flight weather  late
# 0      대한      맑음     5
# 1    아시아나       비    15
# 2    아시아나       눈    30
# 3      대한      낙뢰    60
# ...
train = pd.get_dummies(df, drop_first=True)
X = train[train.columns[1:]].to_numpy()
Y = train[train.columns[0]].to_numpy()
train_input, test_input, train_target, test_target = train_test_split(X, Y, random_state=42)
lr = LinearRegression()
lr.fit(train_input, train_target)
print(lr.predict(train_input[:]))
# [18.83109933 60.39705499  2.7542878  ... 18.83109933  8.07223988 12.49248053]
print(lr.score(train_input, train_target))
# 0.7488027412083975
print(lr.score(test_input, test_target))
# 0.7488202375624603
```

<br/>

## 월별 이용객수 지수평활법 시계열 예측

### 월별 이용객수 데이터 전처리

+ https://www.airport.kr/co/ko/cpr/statisticCategoryOfAirline.do#none 에서 2017년 ~ 2021년의 각 항공사 월별 국제선 출발 이용객수 엑셀 데이터 다운로드
+ 다음 코드를 이용하여 엑셀 파일 내용을 전처리하면서 모두 합치기
  + 이용객수가 0인 달은 제거한다.(의미가 없는 달이며, Holt의 지수평활법 시계열 분석에서는 양의 값만 요구하기 때문에)

```python
import pandas as pd
import glob

airline_set = {
    '중국남방항공', 
    '중국동방항공', 
    '델타항공', 
    'KLM네덜란드항공', 
    '대한항공', 
    '카타르항공', 
    '아메리칸항공', 
    '아시아나항공', 
    '루프트한자 독일항공', 
    '에미레이트항공', 
    '캐나다항공', 
    '유나이티드항공', 
    '에어 프랑스',
    '진에어',
    '티웨이항공',
    '제주항공',
    '에어서울'
}

all_data = pd.DataFrame()

for f in glob.glob("./*.xlsx"):
    year, month = f.replace('By_Airline_', '')[2:6], f.replace('By_Airline_', '')[6:8]
    date = year + '-' + month
    df = pd.read_excel(f)
    # 엑셀의 첫 행이 의미 없음
    df = pd.read_excel(f, skiprows=[0])
    # 항공사명이 Unnamed: 0, 인천 공항에서 출발하는 이용객 수가 출발.1이라는 열 이름을 갖고 있다.
    new_df = pd.DataFrame(df.iloc[1:], columns=['Unnamed: 0', '출발.1'])
    # 칼럼 이름 변경
    new_df = new_df.rename(columns={'Unnamed: 0': 'airline', '출발.1': 'passengers'})
    # airline_set에 있는 항공사 데이터만
    con = new_df['airline'].isin(airline_set)
    condition_df = new_df.loc[con]
    condition_df.insert(0, 'date', [date] * condition_df.shape[0])
    condition_df['date'] = pd.to_datetime(condition_df['date'])
    
    all_data = all_data.append(condition_df, ignore_index=True)

# passengers는 이용객수이지만, 현재 float로 소수점 첫째자리가 0으로 나온다. 해당 열의 type을 int로 바꿔준다.
all_data['passengers'] = all_data['passengers'].astype(int)
# 항공사 별로 묶기
groups = all_data.groupby(all_data.airline)
# 각 항공사 이름으로 csv 파일 만들기
for airline in airline_set:
    group = groups.get_group(airline)
    # 0인 값 제거
    condition_not_zero = group[group['passengers'] == 0].index
    group = group.drop(['airline'], axis=1).drop(condition_not_zero).sort_values(by=['date'], axis=0).reset_index(drop=True)
    group.to_csv('./%s.csv' % airline)
```

+ 결과물

```
// 대한항공.csv
,date,passengers
0,2017-01-01,756322
1,2017-02-01,678846
2,2017-03-01,629667
3,2017-04-01,642086
4,2017-05-01,608914
5,2017-06-01,644683
6,2017-07-01,716892
7,2017-08-01,729937
8,2017-09-01,696130
9,2017-10-01,639764
...
```

### 예측

+ `pip install statsmodel` : 지수평활법 관련 모델이 있는 라이브러리 설치
+ 전처리 상태의 데이터는 완전한 시계열 데이터가 아니다.
  + 원본 엑셀 데이터로부터 이상한 인덱스용 칼럼이 딸려와 포함되어 있다. 이를 제거해야 한다.
  + 결측치의 보간이 되어있지 않다. 즉, 2021-05의 데이터가 없다면 아예 이 시간대가 빠져있다. 시계열 데이터는 완벽하게 모든 시간대의 데이터를 갖고 있어야 한다.
    + pandas의 `.resample('M')`를 통해 월 단위로 새로 묶어줄 수 있다.
    + 새로 생긴 달의 이용객수는 NaN인 상태다. `.interpolate()`를 통해 결측치를 보간한다. 방법은 `method='time'`으로 한다.

+ https://rfriend.tistory.com/671를 참고, 총 7개의 지수평활법 모델을 사용해서 테스트를 해보았고, 의미 있는 결과를 내는 것은 참고 사이트 기준 fit3, fit5였다.
  + fit4, fit7도 성능은 좋았지만, 극한의 상황에서 음수값을 예측해버리는 문제가 있었다.
+ 성능 기준은 여러가지가 있으나, 사이트를 참고하여 우리도 MAPE가 낮을수록 성능이 좋다고 판단한다.
+ 이 네 가지 모델로 학습을 하고 가장 test 점수가 높은(MAPE가 가장 낮은) 모델의 향후 3개월 데이터를 받아온다.

```python
import pandas as pd
import numpy as np
from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt
from statsmodels.tsa.holtwinters import ExponentialSmoothing as HWES
from sklearn.metrics import mean_squared_error as MSE 
from sklearn.metrics import mean_absolute_error as MAE


def predict(airline):
    df = pd.read_csv('./%s.csv' % airline, index_col='date', parse_dates=True)
    df = df.drop(['Unnamed: 0'], axis=1)
    # 결측치 보간 필요
    df = df.resample('M').first()
    df = df.interpolate(method='time')
    df_train = df.iloc[:-3]
    df_test = df.iloc[-3:]

    # 주석 처리는 테스트해 본 결과 의미가 크지 않은 모델들
    # fit1 = SimpleExpSmoothing(df_train).fit()
    # fit2 = Holt(df_train).fit()
    fit3 = Holt(df_train, exponential=True).fit()
    # fit4 = Holt(df_train, damped_trend=True).fit()
    fit5 = Holt(df_train, exponential=True, damped_trend=True).fit()
    # fit6 = HWES(df_train, seasonal_periods=12, trend='add', seasonal='add').fit(optimized=True, use_brute=True)
    # fit7 = HWES(df_train, seasonal_periods=12, trend='add', seasonal='mul').fit(optimized=True, use_brute=True)

    # forecast_1 = fit1.forecast(8)
    # forecast_2 = fit2.forecast(8)
    forecast_3 = fit3.forecast(3)
    # forecast_4 = fit4.forecast(8)
    forecast_5 = fit5.forecast(3)
    # forecast_6 = fit6.forecast(8)
    # forecast_7 = fit7.forecast(8)

    def MAPE(y_test, y_pred): 
        y_test, y_pred = np.array(y_test), np.array(y_pred)
        return np.mean(np.abs((y_test - y_pred) / y_test)) * 100

    # MAPE 비교표
    # def eval_all(y_test, y_pred, model): 
    #     mape = MAPE(y_test, y_pred)
    #     return [mape]
    #
    #
    # eval_all_df = pd.DataFrame( 
    #     {
    #     # 'SES': eval_all(df_test, forecast_1, fit1), 
    #     # "Holt's": eval_all(df_test, forecast_2, fit2), 
    #     'Exponential': eval_all(df_test, forecast_3, fit3), 
    #     # 'Trend_Add': eval_all(df_test, forecast_4, fit4), 
    #     'Trend_Mult': eval_all(df_test, forecast_5, fit5), 
    #     # 'Trend_Season_Add': eval_all(df_test, forecast_6, fit6), 
    #     # 'Trend_Season_Mult': eval_all(df_test, forecast_7, fit7)
    #     } , 
    #     index=['MAPE'])

    if MAPE(df_test, forecast_3) < MAPE(df_test, forecast_5):
        Holt(df, exponential=True).fit().forecast(3).astype(int).reset_index().rename(columns={'index':'date', 0:'passengers'}).to_csv('./predict_data/%s.csv' % airline)
    else:
        Holt(df, exponential=True, damped_trend=True).fit().forecast(3).astype(int).reset_index().rename(columns={'index':'date', 0:'passengers'}).to_csv('./predict_data/%s.csv' % airline)


airline_set = {
    '중국남방항공', 
    '중국동방항공', 
    '델타항공', 
    'KLM네덜란드항공', 
    '대한항공', 
    '카타르항공', 
    '아메리칸항공', 
    '아시아나항공', 
    '루프트한자 독일항공', 
    '에미레이트항공', 
    '캐나다항공', 
    '유나이티드항공', 
    '에어 프랑스',
    '진에어',
    '티웨이항공',
    '제주항공',
    '에어서울'
}

for airline in airline_set:
    predict(airline)
```

<br/>

## 머신러닝 지연률, 지연시간 예측

### 항공 데이터 전처리

+ 계절 데이터 전처리
+ 항공 데이터 전처리

#### 계절 데이터 전처리

+ 날짜, 도시, 온도, 체감 온도, 등 25개의 열이 있으나 우리에게 필요한 것은 **날짜, 날씨** 뿐이다.
+ wind_speed(풍속) 열을 통해 13m/s가 넘는 날은 날씨를 태풍으로 바꾼다.(우리나라 기상청 태풍 기준)

```python
import pandas as pd
from pandas.io.parsers import read_csv

df = read_csv('./weather.csv')
# 필요 없는 열 삭제
df = df.drop([
    'dt', 'timezone', 'city_name', 'lat', 'lon', 'temp', 'feels_like', 'temp_min' , 'temp_max', 'pressure', 'sea_level', 'grnd_level', 'humidity', 
    'wind_deg', 'rain_1h', 'rain_3h', 'snow_1h', 'snow_3h', 'clouds_all', 'weather_id', 'weather_description', 'weather_icon'
    ], axis=1)
# 풍속이 13이 넘으면 weather_main을 Typhoon으로 수정
df['wind_speed'] = df['wind_speed'].astype(float)
df.loc[(df.wind_speed > 13.0), 'weather_main'] = 'Typhoon'
df = df.drop(['wind_speed'], axis=1)
# 시간대를 우리나라 시간으로 바꾸기
df.rename(columns = {'dt_iso' : 'time', 'weather_main' : 'weather'}, inplace = True)
df['time'] = pd.to_datetime(df['time'].str.replace(' UTC', ''), format='%Y-%m-%d %H:%M:%S %z')
dt_time = pd.DatetimeIndex(df['time'])
dt_time = dt_time.tz_convert('Asia/Seoul')
# 형식 바꾸기
df['time'] = dt_time.strftime('%Y-%m-%d %H:%M:%S')
# 중요: 시간이 중복되는 데이터가 있다. 여기서 중복 제거를 안해주면 이후 전처리에서 데이터프레임 merge 시에 행이 늘어나는 문제 발생
df = df.drop_duplicates(subset=['time'])
df.to_csv('./weather_processed.csv')
```

#### 항공 데이터 전처리

+ 통계용, 머신러닝용, 목적지 리스트용 데이터 3개를 만들고자 한다.

+ 항공사 출도착 데이터, 월별 이용객수 데이터, 인천공항 날씨 데이터 3가지를 가지고 Dataframe으로 처리한다.

+ **통계 데이터** 

  + 날짜, 항공사, 목적지, 월별 이용객수, 상태, 지연시간(분), 지연사유

+ **머신러닝 데이터**

  + 항공사, 목적지, 월별 이용객수, 날씨, 지연여부(0, 1)(로지스틱회귀용), 지연시간(분)(다중선형회귀용)

+ **통계 전처리 단계**

  0. date, airport, togo, type, state열이 빈문자열이면 삭제

  1. 항공사 우리 것으로 필터링

  2. type가 화물인 행 제거

  3. CEB()는 CEB(세부)로 바꾸기

  4. flightNo, type 열 삭제

  5. date열 날짜 타입으로 바꾸고 년, 월, 일 뽑아와서 년, 월로 월별 이용객수 열 추가 -> merge 이용

  6. delayedTime 열 추가, state가 지연일 경우에만 departTime - originTime, 나머지는 0 -> 한 다음 originTime, departTime 열 삭제

+ **머신러닝 전처리 단계**

  ​	1 ~ 6 동일

  7. state열이 취소면 삭제

  8. 년, 월, 일로 날씨 추가, 날씨가 Nan인 경우 삭제 처리

  9. isDelayed 열 추가, 지연일 경우에 1, 출발/취소일 경우에 0

+ 공통
  10. 운행기록이 통계 데이터 기준 500번 이하인 나라는 제거 (머신러닝은 그에 맞춤)
  11. togo를 전부 arrival로 바꿈

```python
import pandas as pd
import glob

# 전처리 필요사항
# 통계용 - 날짜, 항공사, 목적지, 월별 이용객수, 상태, 지연시간(분), 지연사유
# 머신러닝용 - 항공사, 목적지, 월별 이용객수, 날씨, 지연여부(0, 1)(로지스틱회귀용), 지연시간(분)(다중선형회귀용)

# 통계 전처리
# 0. date, airport, togo, type, state열이 빈문자열이면 삭제
# 1. 항공사 우리 것으로 필터링
# 2. type가 화물인 행 제거
# 3. CEB()는 CEB(세부)로 바꾸기
# 4. flightNo, type 열 삭제
# 5. date열 날짜 타입으로 바꾸고 년, 월, 일 뽑아와서 년, 월로 월별 이용객수 열 추가 -> merge 이용
# 6. delayedTime 열 추가, state가 지연일 경우에만 departTime - originTime, 나머지는 0 -> 한 다음 originTime, departTime 열 삭제

# 머신러닝 전처리
# 1 ~ 6 동일
# 7. state열이 취소, 회항이면 삭제
# 8. 년, 월, 일로 날씨 추가
# 9. isDelayed 열 추가, 지연일 경우에 1, 출발/취소일 경우에 0

# 공통
# 10. 추가 - 운행기록이 통계 데이터 기준 500번 이하인 나라는 제거 (머신러닝은 그에 맞춤)
# 11. 추가 - 'togo' column 'arrival'로 수정
# 목적지 모으기(DB용)
# 목적지 열 csv뽑기

airline_set = {
    '중국남방항공', 
    '중국동방항공', 
    '델타항공', 
    '네덜란드항공', 
    '대한항공', 
    '카타르항공', 
    '아메리칸항공', 
    '아시아나항공', 
    '독일항공', 
    '에미레이트항공', 
    '캐나다항공', 
    '유나이티드항공', 
    '프랑스항공',
    '진에어',
    '티웨이항공',
    '제주항공',
    '에어서울'
}

# 월별 이용객수 데이터 전부 합치기
df_passengers = pd.DataFrame()
airline_list = [
    '네덜란드항공', '대한항공', '델타항공', '독일항공', '아메리칸항공', '아시아나항공', '에미레이트항공', '프랑스항공', '에어서울', 
    '유나이티드항공', '제주항공', '중국남방항공', '중국동방항공', '진에어', '카타르항공', '캐나다항공', '티웨이항공']

for idx, f in enumerate(glob.glob('./passengers/*.csv')):
    df = pd.read_csv(f)
    df.insert(2, 'airline', [airline_list[idx]] * df.shape[0])
    df_passengers = pd.concat([df_passengers, df])

df_passengers.drop(['Unnamed: 0'], axis = 1, inplace = True)
df_passengers['date'] = pd.to_datetime(df_passengers['date'], format='%Y-%m-%d')
df_passengers['year'] = pd.DatetimeIndex(df_passengers['date']).year
df_passengers['month'] = pd.DatetimeIndex(df_passengers['date']).month

# 항공 데이터 전처리
df_statistics = pd.DataFrame()
df_ml = pd.DataFrame()

for f in glob.glob('./data/*.csv'):
    df = pd.read_csv(f)
    # 0.
    df.dropna(subset=['date', 'airline', 'togo', 'type', 'state'], inplace=True)

    # 1.
    df = df.loc[df['airline'].isin(airline_set)]

    # 2.
    condition_type = df[df['type'] == '화물'].index
    df = df.drop(condition_type)

    # 3.
    df.loc[(df.togo == 'CEB()'), 'togo'] = 'CEB(세부)'

    # 4.
    df = df.drop(columns=['flightNo', 'type'])
    
    # 5.
    # https://blog.naver.com/PostView.nhn?blogId=wideeyed&logNo=221535156243
    df['date'] = pd.to_datetime(df['date'], format='%Y%m%d')
    df['year'] = pd.DatetimeIndex(df['date']).year
    df['month'] = pd.DatetimeIndex(df['date']).month
    df = pd.merge(left=df, right=df_passengers, how='left', on=['year', 'month', 'airline'], sort=False)
    df.dropna(subset=['passengers'], inplace=True)
    df['passengers'] = df['passengers'].astype(int)

    # 6.
    df_delayed = df[df['state'] == '지연']
    df_not_delayed = df[df['state'] != '지연']
    # 지연인데도 출발 시각이 안찍힌 아이들
    df_delayed = df_delayed[df_delayed['departTime'] != ':']
    # 날짜와 시간을 합치는 방법(중요)
    temp_dt = df_delayed['departTime'] # 머신러닝에서 df_not_delayed 부분까지 일괄적으로 날짜 형식을 바꿔주기 위해 저장해둠
    df_delayed['departTime'] = pd.to_timedelta(df_delayed['departTime'] + ':00') + df_delayed['date_x']
    df_delayed['originTime'] = pd.to_timedelta(df_delayed['originTime'] + ':00') + df_delayed['date_x']
    df_delayed['delayedTime'] = df_delayed['departTime'] - df_delayed['originTime']
    df_delayed['delayedTime'] = df_delayed['delayedTime'].astype('timedelta64[m]').astype(int)
    df_not_delayed['delayedTime'] = [0] * df_not_delayed.shape[0]
    df = pd.concat([df_delayed, df_not_delayed])
    df.rename(columns = {'date_x' : 'date'}, inplace = True)
    df = df.drop(['originTime', 'departTime', 'date_y', 'year', 'month'], axis=1)
    # 머신러닝에서 쓰기 위해 복원
    df_delayed['departTime'] = temp_dt
    df2 = pd.concat([df_delayed, df_not_delayed])
    df2.rename(columns = {'date_x' : 'date'}, inplace = True)
    df2 = df2.drop(['originTime', 'date_y', 'year', 'month'], axis=1)

    # 머신러닝
    # 7. 
    condition_state = df2[(df2['state'] == '취소') | (df2['state'] == '회항')].index
    df2 = df2.drop(condition_state)

    # 8.
    # weather.csv를 weather_preprocessing.py를 통해 전처리한 상태의 Dataframe을 갖고 merge한다.
    # 이때 날씨 정보의 merge 기준 시간 형태는 2017-01-01 09:00:00
    # 이와 같은 형식을 갖도록 departTime을 time열로 수정한다.
    df2.rename(columns = {'departTime' : 'time'}, inplace = True)
    # 시간 형태 변경
    df2['time'] = pd.to_timedelta(df2['time'] + ':00') + df2['date']
    # 분 날리기
    df2['time'] = df2.time.dt.round('H')
    # weather_processed.csv를 로드하고 merge하기
    df_weather = pd.read_csv('./weather_processed.csv')
    df_weather['time'] = pd.to_datetime(df_weather['time'], format='%Y-%m-%d %H:%M:%S')
    df2 = pd.merge(left=df2, right=df_weather, how='left', on=['time'], sort=False)
    df2 = df2.drop(['Unnamed: 0', 'time', 'date', 'reason'], axis=1)
    # 날씨가 Nan인 값이 있다.
    df2.dropna(subset=['weather'], inplace=True)

    # 9.
    df2.loc[(df2.state == '지연'), 'state'] = 1
    df2.loc[(df2.state == '출발'), 'state'] = 0

    # 열 순서 바꾸기
    df2 = df2[['airline', 'togo', 'passengers', 'weather', 'state', 'delayedTime']]
    
    df_statistics = df_statistics.append(df, ignore_index=True)
    df_ml = df_ml.append(df2, ignore_index=True)

# 500번 운항 미만 나라 컷
df_statistics = df_statistics[df_statistics.groupby('togo')['togo'].transform('count').ge(500)]
df_arrival = df_statistics['togo'].to_frame().drop_duplicates()

# 11. togo => arrival, delayedTime => delayed_time
df_ml.rename(columns = {'togo': 'arrival', 'delayedTime': 'delayed_time'}, inplace=True)
df_statistics.rename(columns = {'togo' : 'arrival', 'delayedTime': 'delayed_time'}, inplace = True)
df_arrival.rename(columns = {'togo' : 'arrival'}, inplace = True)

# 취한 나라 리스트
arrival_list = df_arrival['arrival'].values.tolist()
df_ml = df_ml.loc[df_ml['arrival'].isin(arrival_list)]
df_statistics.to_csv('./statistics_data.csv')
df_ml.to_csv('./ml_data.csv')
df_arrival.to_csv('./arrival_data.csv')
```

### 지연률 예측(로지스틱회귀)

+ 초기 예상했던 모델과는 변경점이 많아졌다.
  + 원핫인코딩에 있어서 pandas의 `get_dummies()`를 사용하지 않고, sklearrn의 LabelEncode와 OnehotEncoder를 사용한다.
    + **그 이유가 굉장히 중요하다.**
    + 우리는 모델을 미리 만들어놓고, 이 모델을 따로 저장해놨다가 사용해야 한다.
    + 동시에, 원핫인코딩에 사용된 **인코더 정보** 자체를 저장해놔야 우리가 예측을 하고자 입력값을 넣을때 변환할 수 있다.
    + 즉, `[['제주항공', 'TAO(청도)', 'Mist', 178981]]` 같은 데이터는 원핫인코딩을 하면 카테고리가 많기 때문에 매우 많은 1과 0으로 표현된다.(정확히는 149개의 1과 0, 178981로 표현된다.)
    + 따라서 사용자로부터 받은 입력을 우리가 149개의 1과 0으로 표현하는 것은 불가능하다.
    + 따라서, `[['제주항공', 'TAO(청도)', 'Mist', 178981]]`와 같은 형태로 입력을 보내면 알아서 이를 인코딩하게 한 뒤 모델에 입력값을 보내야 하며, 이 때문에 인코더 자체를 저장해야 하고, 그러기 위해서는 `joblib`을 사용해서 sklearn의 인코더 정보들을 저장해야 한다.

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
import joblib
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

# 이 dict들이 인코더의 정보
labelencoder_dict = {}
onehotencoder_dict = {}
df = pd.read_csv('./ml_data.csv', index_col = 0)
# 우리가 필요한 독립변수들은 airline, arrival, weather, passengers
# 하지만 passengers는 원핫인코딩을 할 필요가 없기 때문에 먼저 앞의 세 변수들을 원핫인코딩하고 그 결과에 붙여넣어 독립변수 array를 완성한다.
df_X = df.drop(['state', 'delayed_time', 'passengers'], axis=1)
X = None
for i in range(0, df_X.shape[1]):
    label_encoder = LabelEncoder()
    labelencoder_dict[i] = label_encoder
    feature = label_encoder.fit_transform(df_X.iloc[:,i].astype(str))
    feature = feature.reshape(df_X.shape[0], 1)
    # drop='first'를 해줘야 원핫인코딩으로 인한 다중공선성이 생기지 않는다.
    onehot_encoder = OneHotEncoder(drop='first', sparse=False)
    feature = onehot_encoder.fit_transform(feature)
    onehotencoder_dict[i] = onehot_encoder
    if X is None:
        X = feature
    else:
        X = np.concatenate((X, feature), axis=1)

# 원핫인코딩 결과에 passengers 열 추가
X = np.concatenate((X, df['passengers'].to_numpy().reshape(-1, 1)), axis=1)
Y = df[df.columns[4]].to_numpy()
# 지수표현 제거
np.set_printoptions(precision=6, suppress=True)

# 학습
train_input, test_input, train_target, test_target = train_test_split(X, Y, random_state=42)
lr = LogisticRegression()
lr.fit(train_input, train_target)

# 저장
joblib.dump(lr, './delay_rate_predict.pkl')
joblib.dump(labelencoder_dict, './labelencoder_dict.pkl')
joblib.dump(onehotencoder_dict, './onehotencoder_dict.pkl')
```

+ 예측 예시 코드

```python
import pandas as pd
import numpy as np
import joblib

# 인코더 정보를 가져와서 우리가 편한 입력값을 원핫인코딩 값으로 바꿔주는 함수
def getEncoded(data,labelencoder_dict,onehotencoder_dict):
    # except passengers
    data_exc = data.iloc[:, :-1]
    encoded_x = None
    for i in range(0,data_exc.shape[1]):
        label_encoder =  labelencoder_dict[i]
        feature = label_encoder.transform(data_exc.iloc[:,i])
        feature = feature.reshape(data_exc.shape[0], 1)
        onehot_encoder = onehotencoder_dict[i]
        feature = onehot_encoder.transform(feature)
        if encoded_x is None:
            encoded_x = feature
        else:
            encoded_x = np.concatenate((encoded_x, feature), axis=1)

    encoded_x = np.concatenate((encoded_x, data.iloc[:, -1].to_numpy().reshape(-1, 1)), axis=1)

    return encoded_x


model = joblib.load('./delay_rate_predict.pkl')
labelencoder = joblib.load('./labelencoder_dict.pkl')
onehotencoder = joblib.load('./onehotencoder_dict.pkl')
data = pd.DataFrame([['제주항공', 'TAO(청도)', 'Mist', 178981]], columns = ['airline', 'arrival', 'weather', 'passengers'])
input_data = getEncoded(data, labelencoder, onehotencoder)
print(model.predict_proba(input_data))
```

### 지연시간예측(다중선형회귀)

+ **이 모델은 사용할 수 없다. 정확도가 2%다...**
  + 원핫인코딩이 다중선형회귀에서 매우 안좋다는 것은 알고 있었지만, 이렇게 정확도가 낮을줄 몰랐다.
  + 지연시간 예측은 제외하고 지연률만 예측해야 할 것 같다.

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
import joblib


labelencoder_dict = {}
onehotencoder_dict = {}
df = pd.read_csv('./ml_data.csv', index_col = 0)
df_X = df.drop(['state', 'delayed_time', 'passengers'], axis=1)
X = None
for i in range(0, df_X.shape[1]):
    label_encoder = LabelEncoder()
    labelencoder_dict[i] = label_encoder
    feature = label_encoder.fit_transform(df_X.iloc[:,i].astype(str))
    feature = feature.reshape(df_X.shape[0], 1)
    onehot_encoder = OneHotEncoder(drop='first', sparse=False)
    feature = onehot_encoder.fit_transform(feature)
    onehotencoder_dict[i] = onehot_encoder
    if X is None:
      X = feature
    else:
      X = np.concatenate((X, feature), axis=1)

X = np.concatenate((X, df['passengers'].to_numpy().reshape(-1, 1)), axis=1)
Y = df[df.columns[5]].to_numpy()
np.set_printoptions(precision=6, suppress=True)

train_input, test_input, train_target, test_target = train_test_split(X, Y, random_state=42)
lr = LinearRegression()
lr.fit(train_input, train_target)

print(lr.score(train_input, train_target))
print(lr.score(test_input, test_target))
# 0.024057673058971774
# 0.02313417559655917
```

