# 통계 종류

## 리스트 페이지

+ 현재 목적지로의 총 운항 횟수(고려) | 현재 목적지로의 지연률(통계) | 현재 목적지로의 평균 지연시간  (텍스트) | 현재 목적지로의 지연시간(예측) 

<br/>

## 상세 페이지

> https://ichi.pro/ko/django-mich-chart-jsleul-sayonghayeo-daehwa-hyeong-deiteo-sigaghwa-mandeulgi-154262534911758

+ 리뷰 워드 클라우드
+ 항공사의 통합 지연률 | 현재 목적지로의 총 운항 횟수 | 현재 목적지로의 지연률(통계) | 현재 목적지로의 평균 지연시간  (텍스트)
+ 10분 이내 출발율 | 30분 이내 출발율 | 30분 초과 지연 (텍스트)
+ **항공사의 지연시간 평균 시계열 막대 차트** | **항공사의 월별 이용객수 추이 시계열 꺾은선 차트** | **항공사의 통합 지연 사유 파이차트** 
+ **해당 목적지로의 지연 사유 파이차트** | **지연 사유별 평균 지연 시간 막대 그래프** 
+ 머신러닝 그래프
  + 변수 3개(도착지, 항공사 + 기상 / 이용객)
    + **해당 목적지로의 기상별 지연시간 예측 (그래프)**
    + **해당 목적지로의 월별(이용객별) 지연시간 예측  (월별/이용객수별 그래프)**
  + 변수 4개(도착지, 항공사, 기상, 이용객)
    + **해당 목적지로의 오늘 기상, 이달의 이용객수를 기반으로 한 지연률, 지연시간 예측값**

<br/>

## 머신 러닝 모델

> 지수평활법, Multivariable Linear Regression

+ 원핫인코딩을 통해 범주형 변수인 도착지, 항공사, 기상을 수치값으로 변환

+ 올해/향후 12개월 월별 이용객수 예측

  + 지수평활법 모형 훈련 및 예측
  + https://rfriend.tistory.com/671
  + https://statkclee.github.io/statistics/stat-time-series-forecast.html
  + MAPE가 가장 작은 모델을 사용

+ 해당 목적지로의 기상별 지연시간 예측

  + ```
    H(도착지, 항공사, 기상) = w1*도착지 + w2*항공사 + w3*기상 + b
    ```

  + 각 기상(비, 눈, 태풍, 낙뢰 등) 별로 머신러닝 모델을 통해 H(x)값을 구한 후, 이를 그래프로 표현한다.

+ 해당 목적지로의 월별(이용객별) 지연시간 예측

  + ```
    H(도착지, 항공사, 월별 이용객수) = w1*도착지 + w2*항공사 + w3*월별 이용객수 + b
    ```

  + 각 월별 이용객수를 통해 향후 12개월의 지연시간을 예측하고 이를 그래프로 표현한다.

+ 해당 목적지로의 오늘 기상, 이달의 이용객수를 기반으로 한 지연시간 예측

  + ```
    H(도착지, 항공사, 기상, 월별 이용객수) = w1*도착지 + w2*항공사 + w3*기상 + w4*월별 이용객수 + b
    ```

  + 4개의 변수를 사용한 모델을 만들고, 각 값을 넣어 예측값을 도출

<br/>

## 항공 데이터 셋 예시

### 항공기 출발 데이터

https://www.notion.so/jiu-park/bfcc7248ca1844deb2bcdb2f16a9178f#e733620d21f34eccb40d990e4608763d

| 날짜       | 목적지      | 항공사       | 계획시각 | 출발시각 | 지연시간(분) | 지연여부 | 지연사유              |
| ---------- | ----------- | ------------ | -------- | -------- | ------------ | -------- | --------------------- |
| 2021-09-15 | NGO(나고야) | 대한항공     | 08:10    | 08:15    | 5            | N        | N                     |
| 2021-09-14 | CGQ(장춘)   | 아시아나항공 | 08:10    | 09:42    | 92           | Y        | 기상-시정에 의한 지연 |

### 월별 이용객수 데이터

https://www.notion.so/jiu-park/bfcc7248ca1844deb2bcdb2f16a9178f#f5db3bcb94bd49e090036c8aebe79362

| 년도 | 월   | 항공사   | 여객수 |
| ---- | ---- | -------- | ------ |
| 2021 | 8    | 대한항공 | 534847 |

### 기상 데이터 (40년치 데이터 : 시간별로 데이터 존재)

https://www.notion.so/jiu-park/bfcc7248ca1844deb2bcdb2f16a9178f#13aea472c0be44bbb252cf564cd3c4cf

| 날짜       | 기상 상태 |
| ---------- | --------- |
| 2021-09-15 | Clear Sky |

<br/>

## 원핫인코딩

+ 특성에 들어있는 고유한 값마다 새로운 dummy 특성을 만드는 방법이다.
+ 원핫인코딩을 통해 범주를 벡터화하여 해당 튜플에서 해당하는 범주만 1, 나머지 범주는 0을 갖도록 할 수 있다.
  + 범주형 변수의 범주가 4개라면 총 4개의 열이 생성된다.
  + ex) 빨, 주, 노, 초이며 현재 튜플이 빨강이라면 빨강만 1, 나머지는 0의 값을 갖는다.
+ 하지만, 이렇게 되면 빨, 주, 노, 초의 열들의 값이 항상 다 더하면 1이 되는 관계를 갖는다.
  + 이러한 선형 관계 때문에 생기는 문제가 **다중공선성**이다.
+ 이를 해결하기 위해서는 위와 같은 `빨 + 주 + 노 + 초 = 1`이라는 관계를 없애줘야 한다.
  + 이때 사용하는 방법이 범주를 벡터화한 열 중 하나를 없애는 것이다. (주로 첫 번째 것을 없앤다. drop_first=True)
  + 즉, 주, 노, 초로만 나눠 놓고 주, 노, 초가 전부 0인 경우 이 튜플이 빨강임을 알 수 있기 때문에 데이터의 문제는 없으면서 선형 관계가 생기지 않는다.
  + https://towardsdatascience.com/one-hot-encoding-multicollinearity-and-the-dummy-variable-trap-b5840be3c41a
  + https://dnai-deny.tistory.com/12
+ 따라서, 결과적으로 범주의 개수가 N개인 범주형 변수를 적절하게 원핫이코딩하면 총 N-1개의 열이 생성된다.

### 어려움

+ 원핫인코딩 시에는 다중공선성을 신경써야 한다는 것
+ 원핫인코딩으로 인해 범주가 너무 많이 나뉘면 칼럼이 많이 생기기 때문에 메모리 문제, 모델이 제대로 해당 범주형 변수를 반영하지 못한다는 문제(구글링 결과 범주가 너무 많으면 모델에서 학습에 별로 영향을 안미치는 변수로 취급한다고 함)
+ 원핫인코딩 자체가 다중선형회귀에 적합하지 않을 수도 있다는 것
  + 따라서, 실제 데이터로 train / test 셋을 나눠서 평가를 해봐야 한다.

<br/>

## 예시 코딩

### 로지스틱 회귀

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
flight = ['대한', '아시아나', '아시아나', '대한', '대한', '진에어', '아시아나', '진에어', '진에어', '진에어', '대한', '아시아나', '아시아나', '대한', '아시아나', '아시아나', '대한', '대한', '대한', '진에어', '진에어', '진에어', '진에어', '진에어', '진에어', '대한', '아시아나', '대한', '아시아나'] * 100000
weather = ['맑음', '비', '눈', '낙뢰', '맑음', '맑음', '맑음', '비', '눈', '눈', '비', '비', '낙뢰', '낙뢰', '눈', '맑음', '맑음', '눈', '비', '맑음', '눈', '비', '낙뢰', '맑음', '비', '비', '눈', '맑음', '낙뢰'] * 100000
late = [0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1] * 100000
cols = ['flight', 'weather', 'late']
df = pd.DataFrame(list(map(list, zip(flight, weather, late))), columns=cols)
# 다중공선성 제거를 위해 pd.get_dummies에서 첫 범주를 삭제
train = pd.get_dummies(df, drop_first=True)
# 0번째 열이 '지연여부'로 들어감
X = train[train.columns[1:]].to_numpy()
Y = train[train.columns[0]].to_numpy()
train_input, test_input, train_target, test_target = train_test_split(X, Y, random_state=42)
lr = LogisticRegression()
lr.fit(train_input, train_target)
np.set_printoptions(precision=6, suppress=True)
print(train_input)
print(lr.predict(train_input[:]))
# [0 0 1 ... 1 0 0]
print(lr.predict_proba(train_input[:]))
# [[0.999865 0.000135]
#  [0.999884 0.000116]
#  [0.000009 0.999991]
#  ...
#  [0.000133 0.999867]
#  [0.999865 0.000135]
#  [0.999856 0.000144]]
print(lr.score(train_input, train_target))
# 0.9654850574712643
print(lr.score(test_input, test_target))
# 0.9656137931034483
```

<br/>

### 다중선형회귀

```python
from sklearn.linear_model import LinearRegression
flight = ['대한', '아시아나', '아시아나', '대한', '대한', '진에어', '아시아나', '진에어', '진에어', '진에어', '대한', '아시아나', '아시아나', '대한', '아시아나', '아시아나', '대한', '대한', '대한', '진에어', '진에어', '진에어', '진에어', '진에어', '진에어', '대한', '아시아나', '대한', '아시아나'] * 1000000
weather = ['맑음', '비', '눈', '낙뢰', '맑음', '맑음', '맑음', '비', '눈', '눈', '비', '비', '낙뢰', '낙뢰', '눈', '맑음', '맑음', '눈', '비', '맑음', '눈', '비', '낙뢰', '맑음', '비', '비', '눈', '맑음', '낙뢰'] * 1000000
late = [5, 15, 30, 60, 3, 4, 10, 20, 25, 35, 17, 10, 50, 100, 50, 10, 2, 25, 13, 0, 20, 12, 45, 6, 17, 17, 28, 3, 30] * 1000000
cols = ['flight', 'weather', 'late']
df = pd.DataFrame(list(map(list, zip(flight, weather, late))), columns=cols)
print(df[:29])
#    flight weather  late
# 0      대한      맑음     5
# 1    아시아나       비    15
# 2    아시아나       눈    30
# 3      대한      낙뢰    60
# ...
train = pd.get_dummies(df, drop_first=True)
X = train[train.columns[1:]].to_numpy()
Y = train[train.columns[0]].to_numpy()
train_input, test_input, train_target, test_target = train_test_split(X, Y, random_state=42)
lr = LinearRegression()
lr.fit(train_input, train_target)
print(lr.predict(train_input[:]))
# [18.83109933 60.39705499  2.7542878  ... 18.83109933  8.07223988 12.49248053]
print(lr.score(train_input, train_target))
# 0.7488027412083975
print(lr.score(test_input, test_target))
# 0.7488202375624603
```

<br/>

## 월별 이용객수 지수평활법 시계열 예측

### 월별 이용객수 데이터 전처리

+ https://www.airport.kr/co/ko/cpr/statisticCategoryOfAirline.do#none 에서 2017년 ~ 2021년의 각 항공사 월별 국제선 출발 이용객수 엑셀 데이터 다운로드
+ 다음 코드를 이용하여 엑셀 파일 내용을 전처리하면서 모두 합치기
  + 이용객수가 0인 달은 제거한다.(의미가 없는 달이며, Holt의 지수평활법 시계열 분석에서는 양의 값만 요구하기 때문에)

```python
import pandas as pd
import glob

airline_set = {
    '중국남방항공', 
    '중국동방항공', 
    '델타항공', 
    'KLM네덜란드항공', 
    '대한항공', 
    '카타르항공', 
    '아메리칸항공', 
    '아시아나항공', 
    '루프트한자 독일항공', 
    '에미레이트항공', 
    '캐나다항공', 
    '유나이티드항공', 
    '에어 프랑스',
    '진에어',
    '티웨이항공',
    '제주항공',
    '에어서울'
}

all_data = pd.DataFrame()

for f in glob.glob("./*.xlsx"):
    year, month = f.replace('By_Airline_', '')[2:6], f.replace('By_Airline_', '')[6:8]
    date = year + '-' + month
    df = pd.read_excel(f)
    # 엑셀의 첫 행이 의미 없음
    df = pd.read_excel(f, skiprows=[0])
    # 항공사명이 Unnamed: 0, 인천 공항에서 출발하는 이용객 수가 출발.1이라는 열 이름을 갖고 있다.
    new_df = pd.DataFrame(df.iloc[1:], columns=['Unnamed: 0', '출발.1'])
    # 칼럼 이름 변경
    new_df = new_df.rename(columns={'Unnamed: 0': 'airline', '출발.1': 'passengers'})
    # airline_set에 있는 항공사 데이터만
    con = new_df['airline'].isin(airline_set)
    condition_df = new_df.loc[con]
    condition_df.insert(0, 'date', [date] * condition_df.shape[0])
    condition_df['date'] = pd.to_datetime(condition_df['date'])
    
    all_data = all_data.append(condition_df, ignore_index=True)

# passengers는 이용객수이지만, 현재 float로 소수점 첫째자리가 0으로 나온다. 해당 열의 type을 int로 바꿔준다.
all_data['passengers'] = all_data['passengers'].astype(int)
# 항공사 별로 묶기
groups = all_data.groupby(all_data.airline)
# 각 항공사 이름으로 csv 파일 만들기
for airline in airline_set:
    group = groups.get_group(airline)
    # 0인 값 제거
    condition_not_zero = group[group['passengers'] == 0].index
    group = group.drop(['airline'], axis=1).drop(condition_not_zero).sort_values(by=['date'], axis=0).reset_index()
    group.to_csv('./%s.csv' % airline)
```

+ 결과물

```
// 대한항공.csv
,date,passengers
0,2017-01-01,756322
1,2017-02-01,678846
2,2017-03-01,629667
3,2017-04-01,642086
4,2017-05-01,608914
5,2017-06-01,644683
6,2017-07-01,716892
7,2017-08-01,729937
8,2017-09-01,696130
9,2017-10-01,639764
...
```

### 예측

+ `pip install statsmodel` : 지수평활법 관련 모델이 있는 라이브러리 설치
+ 전처리 상태의 데이터는 완전한 시계열 데이터가 아니다.
  + 원본 엑셀 데이터로부터 이상한 인덱스용 칼럼이 딸려와 포함되어 있다. 이를 제거해야 한다.
  + 결측치의 보간이 되어있지 않다. 즉, 2021-05의 데이터가 없다면 아예 이 시간대가 빠져있다. 시계열 데이터는 완벽하게 모든 시간대의 데이터를 갖고 있어야 한다.
    + pandas의 `.resample('M')`를 통해 월 단위로 새로 묶어줄 수 있다.
    + 새로 생긴 달의 이용객수는 NaN인 상태다. `.interpolate()`를 통해 결측치를 보간한다. 방법은 `method='time'`으로 한다.

+ https://rfriend.tistory.com/671를 참고, 총 7개의 지수평활법 모델을 사용해서 테스트를 해보았고, 의미 있는 결과를 내는 것은 참고 사이트 기준 fit3, fit5였다.
  + fit4, fit7도 성능은 좋았지만, 극한의 상황에서 음수값을 예측해버리는 문제가 있었다.
+ 성능 기준은 여러가지가 있으나, 사이트를 참고하여 우리도 MAPE가 낮을수록 성능이 좋다고 판단한다.
+ 이 네 가지 모델로 학습을 하고 가장 test 점수가 높은(MAPE가 가장 낮은) 모델의 향후 3개월 데이터를 받아온다.

```python
import pandas as pd
import numpy as np
from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt
from statsmodels.tsa.holtwinters import ExponentialSmoothing as HWES
from sklearn.metrics import mean_squared_error as MSE 
from sklearn.metrics import mean_absolute_error as MAE


def predict(airline):
    df = pd.read_csv('./%s.csv' % airline, index_col='date', parse_dates=True)
    df = df.drop(['Unnamed: 0', 'index'], axis=1)
    # 결측치 보간 필요
    df = df.resample('M').first()
    df = df.interpolate(method='time')
    df_train = df.iloc[:-3]
    df_test = df.iloc[-3:]

    # 주석 처리는 테스트해 본 결과 의미가 크지 않은 모델들
    # fit1 = SimpleExpSmoothing(df_train).fit()
    # fit2 = Holt(df_train).fit()
    fit3 = Holt(df_train, exponential=True).fit()
    # fit4 = Holt(df_train, damped_trend=True).fit()
    fit5 = Holt(df_train, exponential=True, damped_trend=True).fit()
    # fit6 = HWES(df_train, seasonal_periods=12, trend='add', seasonal='add').fit(optimized=True, use_brute=True)
    # fit7 = HWES(df_train, seasonal_periods=12, trend='add', seasonal='mul').fit(optimized=True, use_brute=True)

    # forecast_1 = fit1.forecast(8)
    # forecast_2 = fit2.forecast(8)
    forecast_3 = fit3.forecast(3)
    # forecast_4 = fit4.forecast(8)
    forecast_5 = fit5.forecast(3)
    # forecast_6 = fit6.forecast(8)
    # forecast_7 = fit7.forecast(8)

    def MAPE(y_test, y_pred): 
        y_test, y_pred = np.array(y_test), np.array(y_pred)
        return np.mean(np.abs((y_test - y_pred) / y_test)) * 100

    # MAPE 비교표
    # def eval_all(y_test, y_pred, model): 
    #     mape = MAPE(y_test, y_pred)
    #     return [mape]
    #
    #
    # eval_all_df = pd.DataFrame( 
    #     {
    #     # 'SES': eval_all(df_test, forecast_1, fit1), 
    #     # "Holt's": eval_all(df_test, forecast_2, fit2), 
    #     'Exponential': eval_all(df_test, forecast_3, fit3), 
    #     # 'Trend_Add': eval_all(df_test, forecast_4, fit4), 
    #     'Trend_Mult': eval_all(df_test, forecast_5, fit5), 
    #     # 'Trend_Season_Add': eval_all(df_test, forecast_6, fit6), 
    #     # 'Trend_Season_Mult': eval_all(df_test, forecast_7, fit7)
    #     } , 
    #     index=['MAPE'])

    if MAPE(df_test, forecast_3) < MAPE(df_test, forecast_5):
        Holt(df, exponential=True).fit().forecast(3).astype(int).reset_index().rename(columns={'index':'date', 0:'passengers'}).to_csv('./predict_data/%s.csv' % airline)
    else:
        Holt(df, exponential=True, damped_trend=True).fit().forecast(3).astype(int).reset_index().rename(columns={'index':'date', 0:'passengers'}).to_csv('./predict_data/%s.csv' % airline)


airline_set = {
    '중국남방항공', 
    '중국동방항공', 
    '델타항공', 
    'KLM네덜란드항공', 
    '대한항공', 
    '카타르항공', 
    '아메리칸항공', 
    '아시아나항공', 
    '루프트한자 독일항공', 
    '에미레이트항공', 
    '캐나다항공', 
    '유나이티드항공', 
    '에어 프랑스',
    '진에어',
    '티웨이항공',
    '제주항공',
    '에어서울'
}

for airline in airline_set:
    predict(airline)
```

