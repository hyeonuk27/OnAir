# 통계 종류

## 리스트 페이지

+ 현재 목적지로의 총 운항 횟수(고려) | 현재 목적지로의 지연률(통계) | 현재 목적지로의 평균 지연시간  (텍스트) | 현재 목적지로의 지연시간(예측) 

<br/>

## 상세 페이지

> https://ichi.pro/ko/django-mich-chart-jsleul-sayonghayeo-daehwa-hyeong-deiteo-sigaghwa-mandeulgi-154262534911758

+ 리뷰 워드 클라우드
+ 항공사의 통합 지연률 | 현재 목적지로의 총 운항 횟수 | 현재 목적지로의 지연률(통계) | 현재 목적지로의 평균 지연시간  (텍스트)
+ 10분 이내 출발율 | 30분 이내 출발율 | 30분 초과 지연 (텍스트)
+ **항공사의 지연시간 평균 시계열 막대 차트** | **항공사의 월별 이용객수 추이 시계열 꺾은선 차트** | **항공사의 통합 지연 사유 파이차트** 
+ **해당 목적지로의 지연 사유 파이차트** | **지연 사유별 평균 지연 시간 막대 그래프** 
+ 머신러닝 그래프
  + 변수 3개(도착지, 항공사 + 기상 / 이용객)
    + **해당 목적지로의 기상별 지연시간 예측 (그래프)**
    + **해당 목적지로의 월별(이용객별) 지연시간 예측  (월별/이용객수별 그래프)**
  + 변수 4개(도착지, 항공사, 기상, 이용객)
    + **해당 목적지로의 오늘 기상, 이달의 이용객수를 기반으로 한 지연률, 지연시간 예측값**

<br/>

## 머신 러닝 모델

> 지수평활법, Multivariable Linear Regression

+ 원핫인코딩을 통해 범주형 변수인 도착지, 항공사, 기상을 수치값으로 변환

+ 올해/향후 12개월 월별 이용객수 예측

  + 지수평활법 모형 훈련 및 예측
  + https://rfriend.tistory.com/671
  + https://statkclee.github.io/statistics/stat-time-series-forecast.html
  + RMSE, MAPE, MASE가 가장 작은 모델을 사용

+ 해당 목적지로의 기상별 지연시간 예측

  + ```
    H(도착지, 항공사, 기상) = w1*도착지 + w2*항공사 + w3*기상 + b
    ```

  + 각 기상(비, 눈, 태풍, 낙뢰 등) 별로 머신러닝 모델을 통해 H(x)값을 구한 후, 이를 그래프로 표현한다.

+ 해당 목적지로의 월별(이용객별) 지연시간 예측

  + ```
    H(도착지, 항공사, 월별 이용객수) = w1*도착지 + w2*항공사 + w3*월별 이용객수 + b
    ```

  + 각 월별 이용객수를 통해 향후 12개월의 지연시간을 예측하고 이를 그래프로 표현한다.

+ 해당 목적지로의 오늘 기상, 이달의 이용객수를 기반으로 한 지연시간 예측

  + ```
    H(도착지, 항공사, 기상, 월별 이용객수) = w1*도착지 + w2*항공사 + w3*기상 + w4*월별 이용객수 + b
    ```

  + 4개의 변수를 사용한 모델을 만들고, 각 값을 넣어 예측값을 도출

<br/>

## 항공 데이터 셋 예시

### 항공기 출발 데이터

https://www.notion.so/jiu-park/bfcc7248ca1844deb2bcdb2f16a9178f#e733620d21f34eccb40d990e4608763d

| 날짜       | 목적지      | 항공사       | 계획시각 | 출발시각 | 지연시간(분) | 지연여부 | 지연사유              |
| ---------- | ----------- | ------------ | -------- | -------- | ------------ | -------- | --------------------- |
| 2021-09-15 | NGO(나고야) | 대한항공     | 08:10    | 08:15    | 5            | N        | N                     |
| 2021-09-14 | CGQ(장춘)   | 아시아나항공 | 08:10    | 09:42    | 92           | Y        | 기상-시정에 의한 지연 |

### 월별 이용객수 데이터

https://www.notion.so/jiu-park/bfcc7248ca1844deb2bcdb2f16a9178f#f5db3bcb94bd49e090036c8aebe79362

| 년도 | 월   | 항공사   | 여객수 |
| ---- | ---- | -------- | ------ |
| 2021 | 8    | 대한항공 | 534847 |

### 기상 데이터 (40년치 데이터 : 시간별로 데이터 존재)

https://www.notion.so/jiu-park/bfcc7248ca1844deb2bcdb2f16a9178f#13aea472c0be44bbb252cf564cd3c4cf

| 날짜       | 기상 상태 |
| ---------- | --------- |
| 2021-09-15 | Clear Sky |

<br/>

## 원핫인코딩

+ 특성에 들어있는 고유한 값마다 새로운 dummy 특성을 만드는 방법이다.
+ 원핫인코딩을 통해 범주를 벡터화하여 해당 튜플에서 해당하는 범주만 1, 나머지 범주는 0을 갖도록 할 수 있다.
  + 범주형 변수의 범주가 4개라면 총 4개의 열이 생성된다.
  + ex) 빨, 주, 노, 초이며 현재 튜플이 빨강이라면 빨강만 1, 나머지는 0의 값을 갖는다.
+ 하지만, 이렇게 되면 빨, 주, 노, 초의 열들의 값이 항상 다 더하면 1이 되는 관계를 갖는다.
  + 이러한 선형 관계 때문에 생기는 문제가 **다중공선성**이다.
+ 이를 해결하기 위해서는 위와 같은 `빨 + 주 + 노 + 초 = 1`이라는 관계를 없애줘야 한다.
  + 이때 사용하는 방법이 범주를 벡터화한 열 중 하나를 없애는 것이다. (주로 첫 번째 것을 없앤다. drop_first=True)
  + 즉, 주, 노, 초로만 나눠 놓고 주, 노, 초가 전부 0인 경우 이 튜플이 빨강임을 알 수 있기 때문에 데이터의 문제는 없으면서 선형 관계가 생기지 않는다.
  + https://towardsdatascience.com/one-hot-encoding-multicollinearity-and-the-dummy-variable-trap-b5840be3c41a
  + https://dnai-deny.tistory.com/12
+ 따라서, 결과적으로 범주의 개수가 N개인 범주형 변수를 적절하게 원핫이코딩하면 총 N-1개의 열이 생성된다.

### 어려움

+ 원핫인코딩 시에는 다중공선성을 신경써야 한다는 것
+ 원핫인코딩으로 인해 범주가 너무 많이 나뉘면 칼럼이 많이 생기기 때문에 메모리 문제, 모델이 제대로 해당 범주형 변수를 반영하지 못한다는 문제(구글링 결과 범주가 너무 많으면 모델에서 학습에 별로 영향을 안미치는 변수로 취급한다고 함)
+ 원핫인코딩 자체가 다중선형회귀에 적합하지 않을 수도 있다는 것
  + 따라서, 실제 데이터로 train / test 셋을 나눠서 평가를 해봐야 한다.

<br/>

## 예시 코딩

### 로지스틱 회귀

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
flight = ['대한', '아시아나', '아시아나', '대한', '대한', '진에어', '아시아나', '진에어', '진에어', '진에어', '대한', '아시아나', '아시아나', '대한', '아시아나', '아시아나', '대한', '대한', '대한', '진에어', '진에어', '진에어', '진에어', '진에어', '진에어', '대한', '아시아나', '대한', '아시아나'] * 100000
weather = ['맑음', '비', '눈', '낙뢰', '맑음', '맑음', '맑음', '비', '눈', '눈', '비', '비', '낙뢰', '낙뢰', '눈', '맑음', '맑음', '눈', '비', '맑음', '눈', '비', '낙뢰', '맑음', '비', '비', '눈', '맑음', '낙뢰'] * 100000
late = [0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1] * 100000
cols = ['flight', 'weather', 'late']
df = pd.DataFrame(list(map(list, zip(flight, weather, late))), columns=cols)
# 다중공선성 제거를 위해 pd.get_dummies에서 첫 범주를 삭제
train = pd.get_dummies(df, drop_first=True)
# 0번째 열이 '지연여부'로 들어감
X = train[train.columns[1:]].to_numpy()
Y = train[train.columns[0]].to_numpy()
train_input, test_input, train_target, test_target = train_test_split(X, Y, random_state=42)
lr = LogisticRegression()
lr.fit(train_input, train_target)
np.set_printoptions(precision=6, suppress=True)
print(train_input)
print(lr.predict(train_input[:]))
# [0 0 1 ... 1 0 0]
print(lr.predict_proba(train_input[:]))
# [[0.999865 0.000135]
#  [0.999884 0.000116]
#  [0.000009 0.999991]
#  ...
#  [0.000133 0.999867]
#  [0.999865 0.000135]
#  [0.999856 0.000144]]
print(lr.score(train_input, train_target))
# 0.9654850574712643
print(lr.score(test_input, test_target))
# 0.9656137931034483
```

<br/>

### 다중선형회귀

```python
from sklearn.linear_model import LinearRegression
flight = ['대한', '아시아나', '아시아나', '대한', '대한', '진에어', '아시아나', '진에어', '진에어', '진에어', '대한', '아시아나', '아시아나', '대한', '아시아나', '아시아나', '대한', '대한', '대한', '진에어', '진에어', '진에어', '진에어', '진에어', '진에어', '대한', '아시아나', '대한', '아시아나'] * 1000000
weather = ['맑음', '비', '눈', '낙뢰', '맑음', '맑음', '맑음', '비', '눈', '눈', '비', '비', '낙뢰', '낙뢰', '눈', '맑음', '맑음', '눈', '비', '맑음', '눈', '비', '낙뢰', '맑음', '비', '비', '눈', '맑음', '낙뢰'] * 1000000
late = [5, 15, 30, 60, 3, 4, 10, 20, 25, 35, 17, 10, 50, 100, 50, 10, 2, 25, 13, 0, 20, 12, 45, 6, 17, 17, 28, 3, 30] * 1000000
cols = ['flight', 'weather', 'late']
df = pd.DataFrame(list(map(list, zip(flight, weather, late))), columns=cols)
print(df[:29])
#    flight weather  late
# 0      대한      맑음     5
# 1    아시아나       비    15
# 2    아시아나       눈    30
# 3      대한      낙뢰    60
# ...
train = pd.get_dummies(df, drop_first=True)
X = train[train.columns[1:]].to_numpy()
Y = train[train.columns[0]].to_numpy()
train_input, test_input, train_target, test_target = train_test_split(X, Y, random_state=42)
lr = LinearRegression()
lr.fit(train_input, train_target)
print(lr.predict(train_input[:]))
# [18.83109933 60.39705499  2.7542878  ... 18.83109933  8.07223988 12.49248053]
print(lr.score(train_input, train_target))
# 0.7488027412083975
print(lr.score(test_input, test_target))
# 0.7488202375624603
```

